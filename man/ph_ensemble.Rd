% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ph_ensemble.R
\name{ph_ensemble}
\alias{ph_ensemble}
\title{Classify phenotypes via ensemble learning.}
\usage{
ph_ensemble(
  train_models,
  train_df,
  vali_df,
  test_df,
  class_col = "class",
  resample_method = "boot",
  number = ifelse(grepl("cv", resample_method, ignore.case = TRUE), 10, 25),
  repeats = ifelse(grepl("dcv$", resample_method, ignore.case = TRUE), 3, NA),
  search = "random",
  sampling = NULL,
  n_cores = parallel::detectCores() - 1,
  task = "multi",
  metric = ifelse(task == "multi", "Kappa", "ROC"),
  top_models = 3,
  metalearner = ifelse(task == "multi", "glmnet", "rf"),
  tune_length = 10,
  quiet = FALSE
)
}
\arguments{
\item{train_models}{A \code{list} of at least two \code{train} models.}

\item{train_df}{A \code{data.frame} containing a class column and the training data.}

\item{vali_df}{A \code{data.frame} containing a class column and the validation data.}

\item{test_df}{A \code{data.frame} containing a class column and the test data.}

\item{class_col}{A \code{character} value for the name of the class column. This should be consistent across data frames.}

\item{resample_method}{A \code{character} value for the resampling training method: "boot" (default), "cv", LOOCV", "repeatedcv".}

\item{number}{An \code{integer} value for the number of resampling iterations (25 default for boot) or folds (10 default for cross-validation).}

\item{repeats}{An \code{integer} value for the number of sets of folds for repeated cross-validation.}

\item{search}{A \code{character} value for the hyperparameter search strategy: "random" (default), "grid".}

\item{sampling}{A \code{character} value for the sampling strategy, sometimes used to fix class imbalances: \code{NULL} (default), "up", "down", "smote".}

\item{n_cores}{An \code{integer} value for the number of cores to include in the cluster: detectCores() - 1 (default).}

\item{task}{A \code{character} value for the type of classification \code{task}: "multi" (default), "binary".}

\item{metric}{A \code{character} value for which summary metric should be used to select the optimal model: "ROC" (default for "binary") and "Kappa" (default for "multi")}

\item{top_models}{A \code{numeric} value for the top n training models to ensemble: 3 (default). Every training model is ordered according to their final metric value (e.g., "ROC" or "Kappa") and the top n models are selected.}

\item{metalearner}{A \code{character} value for the algorithm used to train the ensemble: "glmnet" (default), "rf". Other methods, such as those listed in ph_train methods, may also be used.}

\item{tune_length}{If \code{search = "random"} (default), this is an \code{integer} value for the maximum number of hyperparameter combinations to test for each training model in the ensemble; if \code{search = "grid"}, this is an \code{integer} value for the number of levels of each hyperparameter to test for each model.}

\item{quiet}{A \code{logical} value for whether progress should be printed: TRUE (default), FALSE.}
}
\value{
A list containing the following components:\tabular{ll}{
\code{ensemble_test_preds} \tab The ensemble predictions for the test set. \cr
\tab \cr
\code{vali_preds} \tab The validation predictions for the top models. \cr
\tab \cr
\code{test_preds} \tab The test predictions for the top models. \cr
\tab \cr
\code{all_test_preds} \tab The test predictions for every successfully trained model. \cr
\tab \cr
\code{all_test_results} \tab The confusion matrix results obtained from comparing the model test predictions (i.e., original models and ensemble) against the actual test classes.  \cr
\tab \cr
\code{ensemble_model} \tab The ensemble \code{train} object. \cr
\tab \cr
\code{var_imps} \tab The ensemble variable importances obtained via weighted averaging. The original train importances are multiplied by the model's importance in the ensemble, then averaged across models and normalized.  \cr
\tab \cr
\code{train_df} \tab The training data frame. \cr
\tab \cr
\code{vali_df} \tab The validation data frame. \cr
\tab \cr
\code{test_df} \tab The test data frame. \cr
\tab \cr
\code{train_models} \tab The \code{train} models for the ensemble. \cr
\tab \cr
\code{ctrl} \tab A \code{trainControl} object. \cr
\tab \cr
\code{metric} \tab The summary metric used to select the optimal model. \cr
\tab \cr
\code{task} \tab The type of classification task. \cr
\tab \cr
\code{tuneLength} \tab The maximum number of hyperparameter combinations ("random") or individual hyperparameter depth ("grid").  \cr
\tab \cr
\code{top_models} \tab The number of top methods selected for the ensemble.  \cr
\tab \cr
\code{metalearner} \tab The algorithm used to train the ensemble. \cr
}
}
\description{
The \code{ph_ensemble} function recruits classification predictions from a list of algorithms to train an ensemble model. This can be a list of manually trained algorithms from \code{train} or, more conveniently, the output from \code{ph_train}. The hyperparameter tuning and model evaluations are handled internally to simplify the ensembling process.
}
